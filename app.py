"""
CNKIèˆ†æƒ…çˆ¬è™«ç³»ç»Ÿ - Webåº”ç”¨
æä¾›å¯è§†åŒ–ç•Œé¢å’ŒAPIæ¥å£
"""
import os
import json
import threading
from datetime import datetime
from pathlib import Path
from flask import Flask, render_template, request, jsonify, send_file
from flask_cors import CORS
from flask_socketio import SocketIO, emit

# å¯¼å…¥çˆ¬è™«æ¨¡å—
from config import Config
from utils import Logger, FileManager
from journal_scraper import JournalScraper
from keyword_scraper import KeywordScraper
from article_downloader import ArticleDownloader
from database import db
from task_manager import task_manager

app = Flask(__name__)
app.config['SECRET_KEY'] = 'cnki_scraper_secret_key'
CORS(app)
socketio = SocketIO(app, cors_allowed_origins="*")

# å…¨å±€å˜é‡
current_task = None
task_status = {
    'running': False,
    'progress': 0,
    'message': '',
    'type': '',
    'results': []
}

class WebLogger:
    """Webæ—¥å¿—ç±»ï¼Œå°†æ—¥å¿—å‘é€åˆ°å‰ç«¯"""
    
    def __init__(self):
        self.logger = Logger.setup_logger("WebApp")
    
    def info(self, message):
        self.logger.info(message)
        socketio.emit('log', {'level': 'info', 'message': message, 'time': datetime.now().strftime('%H:%M:%S')})
    
    def error(self, message):
        self.logger.error(message)
        socketio.emit('log', {'level': 'error', 'message': message, 'time': datetime.now().strftime('%H:%M:%S')})
    
    def warning(self, message):
        self.logger.warning(message)
        socketio.emit('log', {'level': 'warning', 'message': message, 'time': datetime.now().strftime('%H:%M:%S')})

web_logger = WebLogger()

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/api/status')
def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        # æ£€æŸ¥ChromeDriver
        chrome_driver_path = Config.get_chrome_driver_path_dynamic()
        chrome_driver_exists = Path(chrome_driver_path).exists()
        
        # æ£€æŸ¥ç›®å½•
        Config.ensure_directories()
        
        # ç»Ÿè®¡æ–‡ä»¶
        link_files = list(Config.LINK_DIR.glob('*.txt'))
        save_files = []
        for save_dir in Config.SAVE_DIR.iterdir():
            if save_dir.is_dir():
                save_files.extend(list(save_dir.rglob('*.*')))
        
        # æ£€æŸ¥æœŸåˆŠæ–‡ä»¶
        journal_file_exists = Path(Config.EXCEL_FILE).exists()
        
        status = {
            'chrome_driver': {
                'path': chrome_driver_path,
                'exists': chrome_driver_exists
            },
            'directories': {
                'save_dir': str(Config.SAVE_DIR),
                'link_dir': str(Config.LINK_DIR)
            },
            'files': {
                'journal_file': Config.EXCEL_FILE,
                'journal_exists': journal_file_exists,
                'link_count': len(link_files),
                'download_count': len(save_files)
            },
            'config': {
                'keywords': list(Config.KEYWORDS),
                'result_count': Config.RESULT_COUNT,
                'year_range': Config.YEAR_RANGE,
                'file_type': Config.FILE_TYPE,
                'max_workers': Config.MAX_WORKERS
            },
            'task_status': task_status
        }
        
        return jsonify({'success': True, 'data': status})
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/journal/scrape', methods=['POST'])
def scrape_journal():
    """æœŸåˆŠæ£€ç´¢"""
    global current_task, task_status
    
    if task_status['running']:
        return jsonify({'success': False, 'error': 'å·²æœ‰ä»»åŠ¡åœ¨è¿è¡Œä¸­'})
    
    try:
        data = request.get_json()
        excel_file = data.get('excel_file', Config.EXCEL_FILE)
        start_year = data.get('start_year', Config.YEAR_RANGE[0])
        end_year = data.get('end_year', Config.YEAR_RANGE[1])
        
        # é‡ç½®ä»»åŠ¡çŠ¶æ€
        task_status.update({
            'running': True,
            'progress': 0,
            'message': 'å¼€å§‹æœŸåˆŠæ£€ç´¢...',
            'type': 'journal',
            'results': []
        })
        
        def run_journal_scraper():
            try:
                web_logger.info(f"å¼€å§‹æœŸåˆŠæ£€ç´¢: {excel_file}, å¹´ä»½: {start_year}-{end_year}")
                
                scraper = JournalScraper(excel_file)
                results = scraper.scrape_by_year_range(start_year, end_year)
                
                task_status.update({
                    'running': False,
                    'progress': 100,
                    'message': 'æœŸåˆŠæ£€ç´¢å®Œæˆ',
                    'results': results
                })
                
                web_logger.info(f"æœŸåˆŠæ£€ç´¢å®Œæˆï¼Œå…±å¤„ç† {len(results)} ä¸ªæœŸåˆŠ")
                socketio.emit('task_complete', task_status)
                
            except Exception as e:
                task_status.update({
                    'running': False,
                    'progress': 0,
                    'message': f'æœŸåˆŠæ£€ç´¢å¤±è´¥: {str(e)}'
                })
                web_logger.error(f"æœŸåˆŠæ£€ç´¢å¤±è´¥: {str(e)}")
                socketio.emit('task_error', {'error': str(e)})
        
        current_task = threading.Thread(target=run_journal_scraper)
        current_task.start()
        
        return jsonify({'success': True, 'message': 'æœŸåˆŠæ£€ç´¢ä»»åŠ¡å·²å¯åŠ¨'})
    
    except Exception as e:
        task_status['running'] = False
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/keyword/scrape', methods=['POST'])
def scrape_keyword():
    """å…³é”®è¯æœç´¢"""
    global current_task, task_status
    
    if task_status['running']:
        return jsonify({'success': False, 'error': 'å·²æœ‰ä»»åŠ¡åœ¨è¿è¡Œä¸­'})
    
    try:
        data = request.get_json()
        keywords = data.get('keywords', list(Config.KEYWORDS))
        result_count = data.get('result_count', Config.RESULT_COUNT)
        
        # é‡ç½®ä»»åŠ¡çŠ¶æ€
        task_status.update({
            'running': True,
            'progress': 0,
            'message': 'å¼€å§‹å…³é”®è¯æœç´¢...',
            'type': 'keyword',
            'results': []
        })
        
        def run_keyword_scraper():
            try:
                web_logger.info(f"å¼€å§‹å…³é”®è¯æœç´¢: {keywords}, ç»“æœæ•°é‡: {result_count}")
                
                scraper = KeywordScraper()
                results = scraper.search_keywords(keywords, result_count)
                
                task_status.update({
                    'running': False,
                    'progress': 100,
                    'message': 'å…³é”®è¯æœç´¢å®Œæˆ',
                    'results': results
                })
                
                web_logger.info(f"å…³é”®è¯æœç´¢å®Œæˆï¼Œå…±æœç´¢ {len(keywords)} ä¸ªå…³é”®è¯")
                socketio.emit('task_complete', task_status)
                
            except Exception as e:
                task_status.update({
                    'running': False,
                    'progress': 0,
                    'message': f'å…³é”®è¯æœç´¢å¤±è´¥: {str(e)}'
                })
                web_logger.error(f"å…³é”®è¯æœç´¢å¤±è´¥: {str(e)}")
                socketio.emit('task_error', {'error': str(e)})
        
        current_task = threading.Thread(target=run_keyword_scraper)
        current_task.start()
        
        return jsonify({'success': True, 'message': 'å…³é”®è¯æœç´¢ä»»åŠ¡å·²å¯åŠ¨'})
    
    except Exception as e:
        task_status['running'] = False
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/download/start', methods=['POST'])
def start_download():
    """å¼€å§‹ä¸‹è½½"""
    global current_task, task_status
    
    if task_status['running']:
        return jsonify({'success': False, 'error': 'å·²æœ‰ä»»åŠ¡åœ¨è¿è¡Œä¸­'})
    
    try:
        data = request.get_json()
        max_workers = data.get('max_workers', Config.MAX_WORKERS)
        
        # é‡ç½®ä»»åŠ¡çŠ¶æ€
        task_status.update({
            'running': True,
            'progress': 0,
            'message': 'å¼€å§‹æ–‡ç« ä¸‹è½½...',
            'type': 'download',
            'results': []
        })
        
        def run_downloader():
            try:
                web_logger.info(f"å¼€å§‹æ–‡ç« ä¸‹è½½ï¼Œå¹¶å‘æ•°: {max_workers}")
                
                downloader = ArticleDownloader(max_workers=max_workers)
                results = downloader.download_all_links()
                
                task_status.update({
                    'running': False,
                    'progress': 100,
                    'message': 'æ–‡ç« ä¸‹è½½å®Œæˆ',
                    'results': results
                })
                
                web_logger.info(f"æ–‡ç« ä¸‹è½½å®Œæˆ")
                socketio.emit('task_complete', task_status)
                
            except Exception as e:
                task_status.update({
                    'running': False,
                    'progress': 0,
                    'message': f'æ–‡ç« ä¸‹è½½å¤±è´¥: {str(e)}'
                })
                web_logger.error(f"æ–‡ç« ä¸‹è½½å¤±è´¥: {str(e)}")
                socketio.emit('task_error', {'error': str(e)})
        
        current_task = threading.Thread(target=run_downloader)
        current_task.start()
        
        return jsonify({'success': True, 'message': 'æ–‡ç« ä¸‹è½½ä»»åŠ¡å·²å¯åŠ¨'})
    
    except Exception as e:
        task_status['running'] = False
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/articles', methods=['GET'])
def get_articles():
    """è·å–æ–‡ç« åˆ—è¡¨ï¼ˆæ”¯æŒåˆ†é¡µå’Œæœç´¢ï¼‰"""
    try:
        page = int(request.args.get('page', 1))
        per_page = int(request.args.get('per_page', 20))
        search_query = request.args.get('search', '')
        source_type = request.args.get('source_type', '')
        
        offset = (page - 1) * per_page
        
        articles = db.get_articles(
            limit=per_page,
            offset=offset,
            search_query=search_query if search_query else None,
            source_type=source_type if source_type else None
        )
        
        # è·å–æ€»æ•°
        total_count = db.get_articles_count(
            search_query=search_query if search_query else None,
            source_type=source_type if source_type else None
        )
        
        return jsonify({
            'success': True,
            'articles': articles,
            'page': page,
            'per_page': per_page,
            'total': total_count
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/articles/download', methods=['POST'])
def download_selected_articles():
    """æ‰¹é‡ä¸‹è½½é€‰ä¸­çš„æ–‡ç« """
    global current_task, task_status
    
    if task_status['running']:
        return jsonify({'success': False, 'error': 'å·²æœ‰ä»»åŠ¡åœ¨è¿è¡Œä¸­'})
    
    try:
        data = request.get_json()
        article_ids = data.get('article_ids', [])
        max_workers = data.get('max_workers', Config.MAX_WORKERS)
        
        if not article_ids:
            return jsonify({'success': False, 'error': 'è¯·é€‰æ‹©è¦ä¸‹è½½çš„æ–‡ç« '})
        
        # åˆ›å»ºä¸‹è½½ä»»åŠ¡
        task_id = db.create_download_task(article_ids)
        
        # é‡ç½®ä»»åŠ¡çŠ¶æ€
        task_status.update({
            'running': True,
            'progress': 0,
            'message': f'å¼€å§‹ä¸‹è½½ {len(article_ids)} ç¯‡æ–‡ç« ...',
            'type': 'selective_download',
            'task_id': task_id,
            'total': len(article_ids),
            'completed': 0,
            'failed': 0
        })
        
        def run_selective_download():
            try:
                web_logger.info(f"å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(article_ids)} ç¯‡æ–‡ç« ")
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                db.update_download_task(task_id, status='running')
                
                completed_count = 0
                failed_count = 0
                
                for i, article_id in enumerate(article_ids):
                    try:
                        # è·å–æ–‡ç« ä¿¡æ¯
                        articles = db.get_articles(limit=1, offset=0)
                        article = next((a for a in articles if a['id'] == article_id), None)
                        
                        if not article:
                            failed_count += 1
                            continue
                        
                        # æ›´æ–°æ–‡ç« çŠ¶æ€ä¸ºä¸‹è½½ä¸­
                        db.update_article_status(article_id, 'downloading')
                        
                        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„ä¸‹è½½é€»è¾‘
                        # æš‚æ—¶æ¨¡æ‹Ÿä¸‹è½½è¿‡ç¨‹
                        import time
                        time.sleep(1)  # æ¨¡æ‹Ÿä¸‹è½½æ—¶é—´
                        
                        # æ›´æ–°æ–‡ç« çŠ¶æ€ä¸ºå·²å®Œæˆ
                        db.update_article_status(article_id, 'completed', f"downloads/{article['title']}.pdf")
                        completed_count += 1
                        
                        # æ›´æ–°è¿›åº¦
                        progress = int((i + 1) / len(article_ids) * 100)
                        task_status.update({
                            'progress': progress,
                            'message': f'ä¸‹è½½è¿›åº¦: {i + 1}/{len(article_ids)}',
                            'completed': completed_count,
                            'failed': failed_count
                        })
                        
                        socketio.emit('download_progress', task_status)
                        
                    except Exception as e:
                        web_logger.error(f"ä¸‹è½½æ–‡ç«  {article_id} å¤±è´¥: {e}")
                        db.update_article_status(article_id, 'failed')
                        failed_count += 1
                
                # æ›´æ–°æœ€ç»ˆçŠ¶æ€
                db.update_download_task(task_id, completed_count, failed_count, 'completed')
                
                task_status.update({
                    'running': False,
                    'progress': 100,
                    'message': f'ä¸‹è½½å®Œæˆï¼æˆåŠŸ: {completed_count}, å¤±è´¥: {failed_count}',
                    'completed': completed_count,
                    'failed': failed_count
                })
                
                web_logger.info(f"æ‰¹é‡ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸ: {completed_count}, å¤±è´¥: {failed_count}")
                socketio.emit('task_complete', task_status)
                
            except Exception as e:
                db.update_download_task(task_id, status='failed')
                task_status.update({
                    'running': False,
                    'progress': 0,
                    'message': f'ä¸‹è½½å¤±è´¥: {str(e)}'
                })
                web_logger.error(f"æ‰¹é‡ä¸‹è½½å¤±è´¥: {str(e)}")
                socketio.emit('task_error', {'error': str(e)})
        
        current_task = threading.Thread(target=run_selective_download)
        current_task.start()
        
        return jsonify({
            'success': True, 
            'message': f'æ‰¹é‡ä¸‹è½½ä»»åŠ¡å·²å¯åŠ¨ï¼Œä»»åŠ¡ID: {task_id}',
            'task_id': task_id
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/search/history', methods=['GET'])
def get_search_history():
    """è·å–æœç´¢å†å²"""
    try:
        limit = int(request.args.get('limit', 50))
        history = db.get_search_history(limit)
        
        return jsonify({
            'success': True,
            'history': history
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/download/tasks')
def get_download_tasks():
    """è·å–æ‰€æœ‰ä¸‹è½½ä»»åŠ¡"""
    try:
        tasks = db.get_download_tasks()
        return jsonify({
            'success': True,
            'data': tasks
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/download/task/<int:task_id>', methods=['GET'])
def get_download_task_status(task_id):
    """è·å–ä¸‹è½½ä»»åŠ¡çŠ¶æ€"""
    try:
        task = db.get_download_task(task_id)
        
        if not task:
            return jsonify({'success': False, 'error': 'ä»»åŠ¡ä¸å­˜åœ¨'})
        
        return jsonify({
            'success': True,
            'task': task
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/task/stop', methods=['POST'])
def stop_task():
    """åœæ­¢å½“å‰ä»»åŠ¡"""
    global current_task, task_status
    
    try:
        if current_task and current_task.is_alive():
            # è¿™é‡Œéœ€è¦å®ç°ä»»åŠ¡åœæ­¢é€»è¾‘
            # ç”±äºçº¿ç¨‹æ— æ³•ç›´æ¥åœæ­¢ï¼Œéœ€è¦ä½¿ç”¨æ ‡å¿—ä½æˆ–å…¶ä»–æœºåˆ¶
            task_status.update({
                'running': False,
                'progress': 0,
                'message': 'ä»»åŠ¡å·²åœæ­¢'
            })
            
            web_logger.info("ä»»åŠ¡åœæ­¢è¯·æ±‚å·²å‘é€")
            socketio.emit('task_stopped', {'message': 'ä»»åŠ¡å·²åœæ­¢'})
            
            return jsonify({'success': True, 'message': 'ä»»åŠ¡åœæ­¢è¯·æ±‚å·²å‘é€'})
        else:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡'})
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

# ä»»åŠ¡ç®¡ç†APIç«¯ç‚¹
@app.route('/api/tasks', methods=['GET'])
def get_tasks():
    """è·å–æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨"""
    try:
        tasks = task_manager.get_all_tasks()
        return jsonify({'success': True, 'tasks': tasks})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/tasks/<int:task_id>', methods=['GET'])
def get_task_status(task_id):
    """è·å–ç‰¹å®šä»»åŠ¡çŠ¶æ€"""
    try:
        task = task_manager.get_task(task_id)
        if task:
            return jsonify({'success': True, 'task': task.to_dict()})
        else:
            return jsonify({'success': False, 'error': 'ä»»åŠ¡ä¸å­˜åœ¨'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/tasks/<int:task_id>/pause', methods=['POST'])
def pause_task(task_id):
    """æš‚åœä»»åŠ¡"""
    try:
        success = task_manager.pause_task(task_id)
        if success:
            socketio.emit('task_paused', {'task_id': task_id})
            return jsonify({'success': True, 'message': 'ä»»åŠ¡å·²æš‚åœ'})
        else:
            return jsonify({'success': False, 'error': 'æš‚åœä»»åŠ¡å¤±è´¥'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/tasks/<int:task_id>/resume', methods=['POST'])
def resume_task(task_id):
    """æ¢å¤ä»»åŠ¡"""
    try:
        success = task_manager.resume_task(task_id)
        if success:
            socketio.emit('task_resumed', {'task_id': task_id})
            return jsonify({'success': True, 'message': 'ä»»åŠ¡å·²æ¢å¤'})
        else:
            return jsonify({'success': False, 'error': 'æ¢å¤ä»»åŠ¡å¤±è´¥'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/tasks/<int:task_id>/stop', methods=['POST'])
def stop_specific_task(task_id):
    """åœæ­¢ç‰¹å®šä»»åŠ¡"""
    try:
        success = task_manager.stop_task(task_id)
        if success:
            socketio.emit('task_stopped', {'task_id': task_id})
            return jsonify({'success': True, 'message': 'ä»»åŠ¡å·²åœæ­¢'})
        else:
            return jsonify({'success': False, 'error': 'åœæ­¢ä»»åŠ¡å¤±è´¥'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/keyword/scrape_with_task', methods=['POST'])
def scrape_keyword_with_task():
    """ä½¿ç”¨ä»»åŠ¡ç®¡ç†å™¨è¿›è¡Œå…³é”®è¯æœç´¢"""
    try:
        data = request.get_json()
        keywords = data.get('keywords', [])
        result_count = data.get('result_count', Config.RESULT_COUNT)
        
        if not keywords:
            return jsonify({'success': False, 'error': 'è¯·æä¾›å…³é”®è¯'})
        
        # åˆ›å»ºå…³é”®è¯æœç´¢å™¨
        scraper = KeywordScraper()
        task_ids = []
        
        # ä¸ºæ¯ä¸ªå…³é”®è¯åˆ›å»ºä»»åŠ¡
        for keyword in keywords:
            task_id = scraper.scrape_keyword_with_task(keyword, result_count)
            task_ids.append(task_id)
        
        return jsonify({
            'success': True, 
            'message': f'å·²åˆ›å»º {len(task_ids)} ä¸ªæœç´¢ä»»åŠ¡',
            'task_ids': task_ids
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/files/links')
def get_link_files():
    """è·å–é“¾æ¥æ–‡ä»¶åˆ—è¡¨"""
    try:
        link_files = []
        for file_path in Config.LINK_DIR.glob('*.txt'):
            file_info = {
                'name': file_path.name,
                'path': str(file_path),
                'size': file_path.stat().st_size,
                'modified': datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')
            }
            link_files.append(file_info)
        
        return jsonify({'success': True, 'data': link_files})
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/files/downloads')
def get_download_files():
    """è·å–ä¸‹è½½æ–‡ä»¶åˆ—è¡¨"""
    try:
        download_files = []
        for save_dir in Config.SAVE_DIR.iterdir():
            if save_dir.is_dir():
                for file_path in save_dir.rglob('*.*'):
                    if file_path.is_file():
                        file_info = {
                            'name': file_path.name,
                            'path': str(file_path),
                            'relative_path': str(file_path.relative_to(Config.SAVE_DIR)),
                            'size': file_path.stat().st_size,
                            'modified': datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                        }
                        download_files.append(file_info)
        
        return jsonify({'success': True, 'data': download_files})
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@socketio.on('connect')
def handle_connect():
    """WebSocketè¿æ¥"""
    web_logger.info('å®¢æˆ·ç«¯å·²è¿æ¥')
    emit('connected', {'message': 'å·²è¿æ¥åˆ°æœåŠ¡å™¨'})

@socketio.on('disconnect')
def handle_disconnect():
    """WebSocketæ–­å¼€è¿æ¥"""
    web_logger.info('å®¢æˆ·ç«¯å·²æ–­å¼€è¿æ¥')

if __name__ == '__main__':
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    Config.ensure_directories()
    
    # åˆ›å»ºæ¨¡æ¿ç›®å½•
    template_dir = Path(__file__).parent / 'templates'
    template_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºé™æ€æ–‡ä»¶ç›®å½•
    static_dir = Path(__file__).parent / 'static'
    static_dir.mkdir(exist_ok=True)
    
    print("ğŸš€ CNKIèˆ†æƒ…çˆ¬è™«ç³»ç»Ÿå¯åŠ¨ä¸­...")
    print("ğŸ“± Webç•Œé¢åœ°å€: http://localhost:5001")
    print("âš¡ æ”¯æŒå®æ—¶æ—¥å¿—å’Œè¿›åº¦æ˜¾ç¤º")
    
    socketio.run(app, host='0.0.0.0', port=5001, debug=True)